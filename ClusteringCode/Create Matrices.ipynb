{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing bibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T19:46:30.612597Z",
     "start_time": "2019-11-11T19:46:27.952347Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from clustering_logs.log2matrix import create_binary_matrix, create_tf_matrix, create_tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T19:46:30.656217Z",
     "start_time": "2019-11-11T19:46:30.615118Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_and_save_matrices(representations, selections, log):\n",
    "    for representation in representations:\n",
    "        for selection in selections:\n",
    "            print('\\n\\n------\\nIniciando processo para:', representation, selection)\n",
    "            current = (log[['number'] + selections[selection]]).dropna()\n",
    "            representations_matrices = create_and_save_matrices(current, representation, selections[selection], \n",
    "                                                                'number', 'feature', \n",
    "                                                                'matrices/%s_%s_'%(representation, selection))\n",
    "\n",
    "    \n",
    "def create_and_save_matrices(df, representation, cols, index_col, feature_col, filename):\n",
    "    def get_filename(counting):\n",
    "        return '%s%s.csv' %(filename, counting)\n",
    "    \n",
    "    def save(df, filename):\n",
    "        if df.shape[1] > 1000:\n",
    "            print('*too big, saving sparse matrix...')\n",
    "            df_columns = list(df.columns)\n",
    "            df_rows_ids = list(df.index)\n",
    "            #df_sparse = sparse.csr_matrix(df.values)\n",
    "            #sparse.save_npz(filename.replace('.csv', '.npz'), df_sparse)\n",
    "            with open(filename.replace('.csv', '-cols.json'), 'w') as f:\n",
    "                json.dump(df_columns,f)\n",
    "            with open(filename.replace('.csv', '-rows.json'), 'w') as f:\n",
    "                json.dump(df_rows_ids,f)\n",
    "        else:\n",
    "            df.to_csv(filename)\n",
    "\n",
    "\n",
    "    if representation == 'individual':\n",
    "        df = get_individual_val_repres(df, cols, index_col)\n",
    "    elif representation == 'combined':\n",
    "        df = get_combined_val_repres(df, cols, index_col)\n",
    "    \n",
    "    print('\\nRepresentacoes criadas, iniciando as matrizes...')\n",
    "    \n",
    "    \n",
    "    matrix = create_binary_matrix(df, index_col, feature_col)\n",
    "    print('Binaria criada (shape %s), salvando...'%str(matrix.shape))\n",
    "    save(matrix, get_filename('binary'))\n",
    "    print('Salva!')\n",
    "    matrix = create_tf_matrix(df, index_col, feature_col)\n",
    "    print('TF criada (shape %s), salvando...'%str(matrix.shape))\n",
    "    save(matrix, get_filename('tf'))\n",
    "    print('Salva!')  \n",
    "    matrix = create_tfidf_matrix(matrix)\n",
    "    print('TDIDF criada (shape %s), salvando...'%str(matrix.shape))\n",
    "    save(matrix, get_filename('tfidf'))\n",
    "    print('Salva!')\n",
    "    \n",
    "\n",
    "def get_combined_val_repres(df, cols, index_col):\n",
    "    \n",
    "    def add_col_name(x):\n",
    "        aux = x.index+'-' + x.astype(str)\n",
    "        x['feature'] = '--'.join(aux)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    df = (df.set_index(index_col)\n",
    "            .apply(lambda x: add_col_name(x), axis = 1)\n",
    "            .reset_index())\n",
    "    return df[[index_col, 'feature']]\n",
    "\n",
    "def get_individual_val_repres(df, cols, index_col):\n",
    "    df_melt = pd.melt(df, id_vars=index_col, value_vars=cols)#.dropna()\n",
    "    df_melt['feature'] = df_melt[['variable', 'value']].astype(str).apply(lambda x: '-'.join(x), axis=1)\n",
    "    return df_melt.drop(columns=['variable', 'value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T19:46:32.276865Z",
     "start_time": "2019-11-11T19:46:30.670461Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (19,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>incident_state</th>\n",
       "      <th>active</th>\n",
       "      <th>reassignment_count</th>\n",
       "      <th>reopen_count</th>\n",
       "      <th>sys_mod_count</th>\n",
       "      <th>made_sla</th>\n",
       "      <th>caller_id</th>\n",
       "      <th>opened_by</th>\n",
       "      <th>opened_at</th>\n",
       "      <th>...</th>\n",
       "      <th>notify</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>rfc</th>\n",
       "      <th>vendor</th>\n",
       "      <th>caused_by</th>\n",
       "      <th>close_code</th>\n",
       "      <th>resolved_by</th>\n",
       "      <th>resolved_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INC0000045</td>\n",
       "      <td>New</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Caller 2222</td>\n",
       "      <td>Opener 6</td>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Service is stable, ok to close ticket</td>\n",
       "      <td>Resolver 137</td>\n",
       "      <td>29/2/16 11:29</td>\n",
       "      <td>2016-03-05 12:00:00</td>\n",
       "      <td>470640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INC0000045</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>Caller 2222</td>\n",
       "      <td>Opener 6</td>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Service is stable, ok to close ticket</td>\n",
       "      <td>Resolver 137</td>\n",
       "      <td>29/2/16 11:29</td>\n",
       "      <td>2016-03-05 12:00:00</td>\n",
       "      <td>470640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INC0000045</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>Caller 2222</td>\n",
       "      <td>Opener 6</td>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Service is stable, ok to close ticket</td>\n",
       "      <td>Resolver 137</td>\n",
       "      <td>29/2/16 11:29</td>\n",
       "      <td>2016-03-05 12:00:00</td>\n",
       "      <td>470640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INC0000045</td>\n",
       "      <td>Closed</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>Caller 2222</td>\n",
       "      <td>Opener 6</td>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Service is stable, ok to close ticket</td>\n",
       "      <td>Resolver 137</td>\n",
       "      <td>29/2/16 11:29</td>\n",
       "      <td>2016-03-05 12:00:00</td>\n",
       "      <td>470640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INC0000047</td>\n",
       "      <td>New</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Caller 2222</td>\n",
       "      <td>Opener 152</td>\n",
       "      <td>2016-02-29 04:40:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Service is stable, ok to close ticket</td>\n",
       "      <td>Resolver 72</td>\n",
       "      <td>1/3/16 9:52</td>\n",
       "      <td>2016-03-06 10:00:00</td>\n",
       "      <td>537600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number incident_state  active  reassignment_count  reopen_count  \\\n",
       "0  INC0000045            New    True                   0             0   \n",
       "1  INC0000045       Resolved    True                   0             0   \n",
       "2  INC0000045       Resolved    True                   0             0   \n",
       "3  INC0000045         Closed   False                   0             0   \n",
       "4  INC0000047            New    True                   0             0   \n",
       "\n",
       "   sys_mod_count  made_sla    caller_id   opened_by            opened_at  \\\n",
       "0              0      True  Caller 2222    Opener 6  2016-02-29 01:16:00   \n",
       "1              2      True  Caller 2222    Opener 6  2016-02-29 01:16:00   \n",
       "2              3      True  Caller 2222    Opener 6  2016-02-29 01:16:00   \n",
       "3              4      True  Caller 2222    Opener 6  2016-02-29 01:16:00   \n",
       "4              0      True  Caller 2222  Opener 152  2016-02-29 04:40:00   \n",
       "\n",
       "     ...            notify problem_id  rfc vendor caused_by  \\\n",
       "0    ...     Do Not Notify        NaN  NaN    NaN       NaN   \n",
       "1    ...     Do Not Notify        NaN  NaN    NaN       NaN   \n",
       "2    ...     Do Not Notify        NaN  NaN    NaN       NaN   \n",
       "3    ...     Do Not Notify        NaN  NaN    NaN       NaN   \n",
       "4    ...     Do Not Notify        NaN  NaN    NaN       NaN   \n",
       "\n",
       "                              close_code   resolved_by    resolved_at  \\\n",
       "0  Service is stable, ok to close ticket  Resolver 137  29/2/16 11:29   \n",
       "1  Service is stable, ok to close ticket  Resolver 137  29/2/16 11:29   \n",
       "2  Service is stable, ok to close ticket  Resolver 137  29/2/16 11:29   \n",
       "3  Service is stable, ok to close ticket  Resolver 137  29/2/16 11:29   \n",
       "4  Service is stable, ok to close ticket   Resolver 72    1/3/16 9:52   \n",
       "\n",
       "             closed_at  duration  \n",
       "0  2016-03-05 12:00:00  470640.0  \n",
       "1  2016-03-05 12:00:00  470640.0  \n",
       "2  2016-03-05 12:00:00  470640.0  \n",
       "3  2016-03-05 12:00:00  470640.0  \n",
       "4  2016-03-06 10:00:00  537600.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv(\"../datasets/incidentLog/incident_evt_log-processed1-withdurations.csv\")\n",
    "log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get matrices to all combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T03:38:06.804844Z",
     "start_time": "2019-09-09T03:26:46.606757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------\n",
      "Iniciando processo para: combined alg1\n",
      "\n",
      "Representacoes criadas, iniciando as matrizes...\n",
      "Binaria criada (shape (24255, 20356)), salvando...\n",
      "*too big, saving sparse matrix...\n",
      "Salva!\n",
      "TF criada (shape (24255, 20356)), salvando...\n",
      "*too big, saving sparse matrix...\n",
      "Salva!\n",
      "TDIDF criada (shape (24255, 20356)), salvando...\n",
      "*too big, saving sparse matrix...\n",
      "Salva!\n"
     ]
    }
   ],
   "source": [
    "representations = ['combined'] #['individual', 'combined']\n",
    "selections={#'specialist': ['incident_state', 'category', 'priority'], \n",
    "            'alg1': ['caller_id', 'assigned_to']}#, \n",
    "            #'alg2': ['incident_state', 'location']}\n",
    "#matrices = get_and_save_matrices(representations, selections, log)\n",
    "get_and_save_matrices(representations, selections, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T08:39:51.999290Z",
     "start_time": "2019-09-02T08:39:51.984915Z"
    }
   },
   "outputs": [],
   "source": [
    "### Checking the qtt of cases for each atribute selection\n",
    "sizes = {}\n",
    "for matrix in matrices:\n",
    "    log_vector = read_matrix(matrices_path + matrix, index_col='number')\n",
    "    sizes[matrix] = log_vector.drop_duplicates().shape[0]\n",
    "sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates transitions representation \n",
    "Mapping what changes from one entry line of an incident to the next entry line of that same incident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T00:38:37.509033Z",
     "start_time": "2019-08-24T00:38:34.771051Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped = (log1.melt(id_vars=['index','number','sys_updated_at', 'sys_updated_by'])\n",
    "              .groupby(['number','variable','value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T18:40:00.588820Z",
     "start_time": "2019-08-23T16:25:29.805544Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped = (log1.melt(id_vars=['index','number','sys_updated_at', 'sys_updated_by'])\n",
    "              .groupby(['number']))\n",
    "log_transitions = pd.DataFrame({'index': [], 'number': [], 'sys_updated_at': [],'sys_updated_by': [],\n",
    "                                'variable': [],'value': []})\n",
    "for number in list(log1['number']):\n",
    "    group_transitions = grouped.get_group(number).drop_duplicates(['variable','value'])\n",
    "    log_transitions = pd.concat([log_transitions, group_transitions]) \n",
    "    \n",
    "log_transitions.sample(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating combined representation with all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log1 = log1.reset_index()\n",
    "log1_without_open_close = log1.drop(columns=['opened_at','sys_created_at','sys_updated_at','resolved_at','closed_at'])\n",
    "df = get_combined_val_repres(log1_without_open_close, log1.columns,'number')\n",
    "df.to_csv('logs/combined_all.csv')\n",
    "# len(df['number'].unique()) #spec=716 cases, alg1=24117, alg2=1081, all(-ts)=141712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_bin = log2matrix.create_binary_matrix(df,'number',0)\n",
    "matrix_bin.to_csv('matrices/combined_all.csv')\n",
    "print(matrix_bin.reset_index())\n",
    "print(matrix_bin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_bin.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection based on qtt of traces in which the featured has been found\n",
    "Excluding too common or too rare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_traces_qtt = log1_binary.sum()\n",
    "act_traces_qtt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cortando as atividades que aparecem em menos de 1% das traces\n",
    "boxplot = plt.boxplot(act_traces_qtt[act_traces_qtt > 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[item.get_ydata()[1] for item in boxplot['whiskers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_traces_qtt = act_traces_qtt[act_traces_qtt > 100]\n",
    "act_traces_qtt = act_traces_qtt[act_traces_qtt < 1500]\n",
    "useless_features = [col for col in log1_binary.columns if col not in list(act_traces_qtt.index)]\n",
    "log1_binary_filtered = log1_binary.drop(columns=useless_features)\n",
    "list(log1_binary_filtered.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
